---
title: "General description"
weight: 10
description: "General description"
---




## Call for Participation

With the rapid growth of generative music models, such as song generation (composing melodies, lyrics, harmonies, and vocals), we are entering an exciting new era of personalized music, virtual artists, and multimedia content creation. Despite these advancements, the evaluation of the aesthetic quality of generated music remains a challenge. Traditional metrics like pitch accuracy and signal clarity fall short of capturing the complex emotional and artistic dimensions of music that matter most to listeners.
This challenge aims to create a benchmark for assessing the aesthetic quality of automatically generated songs. Participants will develop models that predict human ratings of songs based on musicality, emotional engagement, vocal expressiveness, and overall enjoyment.

**Join us to push the boundaries of song aesthetics evaluation and contribute to the future of generative music!**



## Challenge Overview

The ICASSP 2026 Automatic Song Aesthetics Evaluation Challenge is designed to foster the development of models that can predict human aesthetic ratings of full-length generated songs. We focus on generating songs that align with human perceptions of musicality, emotional depth, and vocal expressiveness. Participants will be tasked with developing models that predict subjective ratings based on audio inputs.
Objective: Create models that can predict human ratings of aesthetic quality in songs, including dimensions like overall musicality, emotional engagement, and vocal expressiveness.


## Track Settings
The competition consists of two tracks:

**Track 1: Overall Musicality Score Prediction** Participants must predict a single holistic aesthetic score for each song, representing an overall musical impression of the song's artistic quality.

**Track 2: Fine-Grained Aesthetic Dimension Prediction** Participants to predict five specific aesthetic dimensions for each song.

## Evaluation
Each track will use correlation-based metrics:
- System-level SRCC and LCC
-  Utterance-level SRCC and LCC for each dimension, with macro-averaged SRCC as the primary evaluation metric.
- More to be considered